# 进程、线程与协程

[//]:参考文档
[//]:https://blog.csdn.net/21cnbao/article/details/108860584
[//]:https://blog.csdn.net/williamgavin/article/details/83062645

<!-- TOC -->

- [进程、线程与协程](#%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%8D%8F%E7%A8%8B)
    - [1. 操作系统的类型](#1-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%B1%BB%E5%9E%8B)
        - [1.1. 批处理操作系统](#11-%E6%89%B9%E5%A4%84%E7%90%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F)
        - [1.2. 分时操作系统](#12-%E5%88%86%E6%97%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F)
        - [1.3. 实时操作系统](#13-%E5%AE%9E%E6%97%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F)
        - [1.4. 网络操作系统](#14-%E7%BD%91%E7%BB%9C%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F)
        - [1.5. 分布式操作系统](#15-%E5%88%86%E5%B8%83%E5%BC%8F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F)
    - [2. 并发与并行](#2-%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C)
    - [3. 同步与异步](#3-%E5%90%8C%E6%AD%A5%E4%B8%8E%E5%BC%82%E6%AD%A5)
    - [4. 进程](#4-%E8%BF%9B%E7%A8%8B)
        - [4.1. 进程上下文](#41-%E8%BF%9B%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87)
        - [4.2. 进程的上下文切换](#42-%E8%BF%9B%E7%A8%8B%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2)
            - [4.2.1. 进程的地址空间切换](#421-%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E5%88%87%E6%8D%A2)
            - [4.2.2. 处理器状态（硬件上下文的切换）](#422-%E5%A4%84%E7%90%86%E5%99%A8%E7%8A%B6%E6%80%81%E7%A1%AC%E4%BB%B6%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9A%84%E5%88%87%E6%8D%A2)
            - [4.2.3. ASID机制](#423-asid%E6%9C%BA%E5%88%B6)
    - [5. 线程](#5-%E7%BA%BF%E7%A8%8B)
        - [5.1. 什么是线程](#51-%E4%BB%80%E4%B9%88%E6%98%AF%E7%BA%BF%E7%A8%8B)
        - [5.2. 线程的分类](#52-%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%88%86%E7%B1%BB)
            - [5.2.1. 用户级线程与内核级线程的区别](#521-%E7%94%A8%E6%88%B7%E7%BA%A7%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%86%85%E6%A0%B8%E7%BA%A7%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB)
        - [5.3. Linux线程模型](#53-linux%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B)
            - [5.3.1. 一对一的线程模型](#531-%E4%B8%80%E5%AF%B9%E4%B8%80%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B)
            - [5.3.2. 多对一的线程模型](#532-%E5%A4%9A%E5%AF%B9%E4%B8%80%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B)
            - [5.3.3. 多对多模型](#533-%E5%A4%9A%E5%AF%B9%E5%A4%9A%E6%A8%A1%E5%9E%8B)
        - [5.4. 线程切换](#54-%E7%BA%BF%E7%A8%8B%E5%88%87%E6%8D%A2)
            - [5.4.1. 线程切换的流程](#541-%E7%BA%BF%E7%A8%8B%E5%88%87%E6%8D%A2%E7%9A%84%E6%B5%81%E7%A8%8B)
            - [5.4.2. 什么时候会发生线程切换](#542-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E5%8F%91%E7%94%9F%E7%BA%BF%E7%A8%8B%E5%88%87%E6%8D%A2)
            - [5.4.3. 线程切换的开销](#543-%E7%BA%BF%E7%A8%8B%E5%88%87%E6%8D%A2%E7%9A%84%E5%BC%80%E9%94%80)
        - [5.5. 多核CPU和多处理器的区别](#55-%E5%A4%9A%E6%A0%B8cpu%E5%92%8C%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E5%8C%BA%E5%88%AB)
    - [6. 协程](#6-%E5%8D%8F%E7%A8%8B)
        - [6.1. 什么是协程](#61-%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%8F%E7%A8%8B)
        - [6.2. 为什么需要协程](#62-%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%8D%8F%E7%A8%8B)
        - [6.3. 协程的切换](#63-%E5%8D%8F%E7%A8%8B%E7%9A%84%E5%88%87%E6%8D%A2)
        - [6.4. 协程的问题](#64-%E5%8D%8F%E7%A8%8B%E7%9A%84%E9%97%AE%E9%A2%98)
            - [6.4.1. 不能在协程中调用阻塞I/O的操作](#641-%E4%B8%8D%E8%83%BD%E5%9C%A8%E5%8D%8F%E7%A8%8B%E4%B8%AD%E8%B0%83%E7%94%A8%E9%98%BB%E5%A1%9Eio%E7%9A%84%E6%93%8D%E4%BD%9C)
            - [6.4.2. 不适用于计算密集型任务](#642-%E4%B8%8D%E9%80%82%E7%94%A8%E4%BA%8E%E8%AE%A1%E7%AE%97%E5%AF%86%E9%9B%86%E5%9E%8B%E4%BB%BB%E5%8A%A1)

<!-- /TOC -->

## 1. 操作系统的类型

- 批处理操作系统（分为单道和多道批处理操作系统）
- 分时操作系统
- 网络操作系统
- 分布式操作系统
- 实时操作系统

### 1.1. 批处理操作系统

**作业**：是用户在一次解题或一个事务处理过程中要求计算机系统所做的工作的集合。包括用户程序、所需的数据及命令等。

**单道批处理操作系统**：是早期计算机系统所配置的一种操作系统类型，其工作流程大致如下：

1. **用户** 将作业递交给 **系统操作员**；
2. **系统操作员** 将若干待处理的作业合并成一批并输入传送到 **外存**；
3. **批处理操作系统** 按一定的原则选择其中的一道作业进入 **内存** 并使之运行；
4. 当作业运行完成或出现错误而无法继续进行下去时，由系统输出有关信息并调入下一道作业运行；
5. 如此反复处理，直到所有作业全部处理完毕为止。

单道操作系统的优缺点：

- **优点**：减少了人工操作的时间，提高了机器的利用率。
- **缺点**：
    1. 每次只能处理一道作业，并且在处理作业时 CPU 必须等待 I/O 完成，因此受到低速 I/O 设备的限制，导致 CPU 的利用率低。（<font color=#FBB05C>因此引入了多道程序处理技术，形成了多道批处理操作系统</font>）
    2. 无交互性：用户一旦将作业提交给系统后，就失去了对作业运行的控制能力。

**多道批处理操作系统**：只是提高了 CPU 的利用率，它允许内存中由多道作业在运行，并且作业可随时被接受进入系统，并存放在外存中，形成后备作业队列，然后由操作系统按一定的原则从后备作业队列中调入一道或多道作业进入内存。

> 注：<font color=Crimson>典型的批处理操作系统有：MVX、DOS/VSE。</font>

### 1.2. 分时操作系统

在分时操作系统中，一台计算机和许多终端设备连接：

1. 每个用户通过自己的终端向系统发出命令，请求完成某项工作；
2. 系统分析从终端设备发来的命令，完成用户提出的请求。
3. 用户根据系统提供的运行结果，向系统提出下一步请求。

这样重复上述交互会话过程，直到用户完成全部工作为止。

分时操作系统中的分时技术：<font color=Crimson>分时操作系统把 CPU 的运行时间划分成很短的时间片，按时间片轮流把处理器分配给各个终端作业使用（时间片轮转法）。若某个终端作业在分配给它的时间片内不能完成其计算，则暂停该终端作业的运行，把处理器让给另一个终端作业使用。等待下一轮时再继续运行。</font>（由于计算机速度很快，各终端作业运行轮转的也很快，这使得每个终端用户感觉自己在独自使用该计算机。）

分时操作系统的优点与特点：

1. **特点**：交互性、多路性、独立性以及及时性。
2. **优点**：便于资源共享和交换信息，为软件开发和工程设计提供了良好的环境。

> 注：<font color=Crimson>典型的分时操作系统有：Windows、Unix、Mac OS 以及 XENIX。</font>

### 1.3. 实时操作系统

**实时操作系统**：是随着计算机应用于实时控制和实时信息处理领域而发展起来的另一种操作系统。实时操作系统能及时响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时设备和实时任务协调一致的工作。（<font color=#FBB05C>实时操作系统对响应时间的要求比分时操作系统更高，一般要求秒级、毫秒级甚至微秒级的响应时间。</font>）

实时操作系统的优点与特点：

1. **特点**：响应及时以及可靠性高

> 注：<font color=Crimson>典型的实时操作系统有：iEmx、Vrtx、RTOS、RT Linux；还有比如机票订购系统、情报检索系统等</font>

### 1.4. 网络操作系统

**网络操作系统**：是向网络计算机提供服务的特殊的操作系统。借由网络达到互相传递数据与各种消息，分为服务器（Server）及客户端（Client）。

服务器的主要功能是管理服务器和网络上的各种资源和网络设备的共用，加以统合并控管流量，避免有瘫痪的可能性，而客户端就是有着能接收服务器所传递的数据来运用的功能，好让客户端可以清楚的搜索所需的资源。

> 注：<font color=Crimson>典型的网络操作系统有：Netware、Windows NT、OS/2 warp等</font>

### 1.5. 分布式操作系统

**分布式操作系统(Distributed Software Systems)**：是支持分布式处理的软件系统，是在由通信网络互联的多处理机体系结构上执行任务的系统。它包括分布式操作系统、分布式程序设计语言及其编译（解释）系统、分布式文件系统和分布式数据库系统等。

> 注：<font color=Crimson>典型的分布式操作系统有：Amoeba</font>

## 2. 并发与并行

**并发**：在操作系统中，某一时间段内，多个程序在同一个CPU上运行，当在任意一个时间点上，只有一个程序在CPU上运行（<font color=Crimson>时间片轮询</font>）。

**并行**：单操作系统有多个 CPU/或一个 CPU 有多个核心时，一个 CPU 处理 A 线程，另一个 CPU 处理 B 线程，两个线程互不抢占 CPU 资源，可以同时运行。这种方式称为并行。

并发与并行的区别：

1. 并发只是宏观上给人感觉时多个程序在同时运行，实际上每时每刻只有一个程序在运行。
2. 并行是每时每刻都可以有多个程序运行。

## 3. 同步与异步

**同步**：是指一个进程/线程在执行某个任务的时候，若该任务处理到中途需要等待其他任务执行完成才能返回信息，那么这个进程/线程就会一直等待下去，不会释放它占有 CPU 资源。

**异步**：是指上述的进程/线程，不会等待，而是将它占有的 CPU 资源释放出来，暂时被操作系统挂起，操作系统继续调用其他进程/线程执行，当被挂起的进程/线程需要的数据准备好时，会有中断来通知操作系统，唤醒之前挂起的进程/线程，让其继续执行。

![PNG-同步与异步的执行示意图Base64](../../pic/operating%20system/PNG-%E5%90%8C%E6%AD%A5%E4%B8%8E%E5%BC%82%E6%AD%A5%E7%9A%84%E6%89%A7%E8%A1%8C%E7%A4%BA%E6%84%8F%E5%9B%BE.jfif)

## 4. 进程

一个进程就是一个<font color=Crimson>正在运行的程序实例，它是 **资源分配的最小单位**。</font>

> 注：<font color=DeepPink>同一时刻执行的进程数，不会超过核心数。单核 CPU 上运行多进程是通过时间片轮询的方式来实现的（见分时操作系统）</font>

### 4.1. 进程上下文

<font color=Crimson>进程上下文是进程执行活动全过程的静态描述。</font>我们把已执行过的进程指令和数据在相关寄存器与堆栈中的内容称为进程上文，把正在执行的指令和数据在寄存器与堆栈中的内容称为进程正文，把待执行的指令和数据在寄存器与堆栈中的内容称为进程下文。

<font color=DeepPink>实际上，Linux 内核中，进程上下文包括进程的虚拟地址空间和硬件上下文。</font>硬件上下文如下图所示：

![PNG-进程的硬件上下文示意图Base64](../../pic/operating%20system/PNG-%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%A1%AC%E4%BB%B6%E4%B8%8A%E4%B8%8B%E6%96%87%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

进程硬件上下文包含了当前cpu的一组寄存器的集合，arm64中使用task_struct结构的thread成员的cpu_context成员来描述，包括x19-x28,sp, pc等。

### 4.2. 进程的上下文切换

进程上下文切换主要涉及到两部分主要过程：**进程地址空间切换** 和 **处理器状态切换**。地址空间切换主要是针对用户进程而言，而处理器状态切换对应于所有的调度单位。

    __schedule  // kernel/sched/core.c
    ->context_switch
        ->switch_mm_irqs_off    // 进程地址空间切换
        ->switch_to // 处理器状态切换

#### 4.2.1. 进程的地址空间切换

**进程地址空间**：指的是进程所拥有的虚拟地址空间，而这个地址空间是假的，是linux内核通过数据结构来描述出来的，从而使得每一个进程都感觉到自己拥有整个内存的假象，cpu访问的指令和数据最终会落实到实际的物理地址，对用进程而言通过缺页异常来分配和建立页表映射。

<font color=DeepPink>进程地址空间内有进程运行的 **指令** 和 **数据**</font>。因此到调度器从其他进程重新切换到我的时候，为了保证当前进程访问的虚拟地址是自己的必须切换地址空间。

实际上，进程地址空间使用 `mm_struct` 结构体来描述，这个结构体被嵌入到进程描述符（我们通常所说的 **进程控制块PCB**）`task_struct` 中，`mm_struct` 结构体将各个 `vma` 组织起来进行管理，其中有一个成员 `pgd` 至关重要，地址空间切换中最重要的是 `pgd` 的设置。

<font color=Crimson>`pgd` 中保存的是进程的页全局目录的虚拟地址</font>，记住保存的是虚拟地址，那么pgd的值是何时被设置的呢？答案是 fork 的时候，如果是创建进程，需要分配设置 `mm_struct`，其中会分配进程页全局目录所在的页，然后将首地址赋值给 `pgd`。

我们来看看进程地址空间究竟是如何切换的，结果会让你大吃一惊（这里暂且不考虑asid机制，后面有机会会在其他文章中讲解）：

    context_switch  // kernel/sched/core.c
    ->switch_mm_irqs_off
        ->switch_mm
        ->__switch_mm
            ->check_and_switch_context
            ->cpu_switch_mm
                ->cpu_do_switch_mm(virt_to_phys(pgd),mm) //arch/arm64/include/asm/mmu_context.h
    
    arch/arm64/mm/proc.S
    158 /*
    159  *      cpu_do_switch_mm(pgd_phys, tsk)
    160  *
    161  *      Set the translation table base pointer to be pgd_phys.
    162  *
    163  *      - pgd_phys - physical address of new TTB
    164  */
    165 ENTRY(cpu_do_switch_mm)
    166         mrs     x2, ttbr1_el1
    167         mmid    x1, x1                          // get mm->context.id
    168         phys_to_ttbr x3, x0
    169
    170 alternative_if ARM64_HAS_CNP
    171         cbz     x1, 1f                          // skip CNP for reserved ASID
    172         orr     x3, x3, #TTBR_CNP_BIT
    173 1:
    174 alternative_else_nop_endif
    175 #ifdef CONFIG_ARM64_SW_TTBR0_PAN
    176         bfi     x3, x1, #48, #16                // set the ASID field in TTBR0
    177 #endif
    178         bfi     x2, x1, #48, #16                // set the ASID
    179         msr     ttbr1_el1, x2                   // in TTBR1 (since TCR.A1 is set)
    180         isb
    181         msr     ttbr0_el1, x3                   // now update TTBR0
    182         isb
    183         b       post_ttbr_update_workaround     // Back to C code...
    184 ENDPROC(cpu_do_switch_mm)

代码中最核心的为181行，最终将进程的 `pgd` 虚拟地址转化为物理地址存放在 `ttbr0_el1` 中，这是用户空间的页表基址寄存器，当访问用户空间地址的时候 `mmu` 会通过这个寄存器来做遍历页表获得物理地址（`ttbr1_el1` 是内核空间的页表基址寄存器，访问内核空间地址时使用，所有进程共享，不需要切换）。完成了这一步，也就完成了进程的地址空间切换，确切的说是进程的虚拟地址空间切换。

其实，地址空间切换过程中，还会清空tlb，防止当前进程虚拟地址转化过程中命中上一个进程的tlb表项，一般会将所有的tlb无效，但是这会导致很大的性能损失，因为新进程被切换进来的时候面对的是全新的空的tlb，造成很大概率的tlb miss,需要重新遍历多级页表，所以arm64在tlb表项中增加了非全局（nG）位区分内核和进程的页表项，使用ASID区分不同进程的页表项，来保证可以在切换地址空间的时候可以不刷tlb，后面会主要讲解ASID技术。

![PNG-进程地址空间的切换示意图Base64](../../pic/operating%20system/PNG-%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E7%9A%84%E5%88%87%E6%8D%A2%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

> 注1：<font color=DeepPink>仅仅切换用户地址空间，内核地址空间由于是共享的不需要切换，也就是为何切换到内核线程不需要也没有地址空间的原因。</font>

> 注2: <font color=#FBB05C>MMU（Memory Management Unit）：内存管理单元，有时也被称为分页内存管理单元（PMMU，Paged Memory Management Unit），它是一种负责处理 CPU 的内存访问请求的硬件。</font>

#### 4.2.2. 处理器状态（硬件上下文的切换）

arm64中切换代码如下：

    switch_to
    ->__switch_to
        ... //浮点寄存器等的切换
        ->cpu_switch_to(prev, next)
 
 
    arch/arm64/kernel/entry.S：
    1032 /*
    1033  * Register switch for AArch64. The callee-saved registers need to be saved
    1034  * and restored. On entry:
    1035  *   x0 = previous task_struct (must be preserved across the switch)
    1036  *   x1 = next task_struct
    1037  * Previous and next are guaranteed not to be the same.
    1038  *
    1039  */
    1040 ENTRY(cpu_switch_to)
    1041         mov     x10, #THREAD_CPU_CONTEXT
    1042         add     x8, x0, x10
    1043         mov     x9, sp
    1044         stp     x19, x20, [x8], #16             // store callee-saved registers
    1045         stp     x21, x22, [x8], #16
    1046         stp     x23, x24, [x8], #16
    1047         stp     x25, x26, [x8], #16
    1048         stp     x27, x28, [x8], #16
    1049         stp     x29, x9, [x8], #16
    1050         str     lr, [x8]
    1051         add     x8, x1, x10
    1052         ldp     x19, x20, [x8], #16             // restore callee-saved registers
    1053         ldp     x21, x22, [x8], #16
    1054         ldp     x23, x24, [x8], #16
    1055         ldp     x25, x26, [x8], #16
    1056         ldp     x27, x28, [x8], #16
    1057         ldp     x29, x9, [x8], #16
    1058         ldr     lr, [x8]
    1059         mov     sp, x9
    1060         msr     sp_el0, x1
    1061         ret
    1062 ENDPROC(cpu_switch_to)

其中x19-x28是arm64 架构规定需要调用保存的寄存器，可以看到处理器状态切换的时候将前一个进程（prev）的x19-x28，fp,sp,pc保存到了进程描述符的cpu_contex中，然后将即将执行的进程(next)描述符的cpu_contex的x19-x28，fp,sp,pc恢复到相应寄存器中，而且将next进程的进程描述符task_struct地址存放在sp_el0中，用于通过current找到当前进程，这样就完成了处理器的状态切换（<font color=Crimson>进程切换都是在内核空间完成</font>）。

由于用户空间通过异常/中断进入内核空间的时候都需要保存现场，也就是保存发生异常/中断时的所有通用寄存器的值，内核会把“现场”保存到每个进程特有的进程内核栈中，并用pt_regs结构来描述，当异常/中断处理完成之后会返回用户空间，返回之前会恢复之前保存的“现场”，用户程序继续执行。所以当进程切换的时候，当前进程被时钟中断打断，将发生中断时的现场保存到进程内核栈（如：sp, lr等），然后会切换到下一个进程，当再次回切换回来的时候，返回用户空间的时候会恢复之前的现场，进程就可以继续执行（执行之前被中断打断的下一条指令，继续使用自己用户态sp），这对于用户进程来说是透明的。

![PNG-进程硬件上下文切换的示意图Base64](../../pic/operating%20system/PNG-%E8%BF%9B%E7%A8%8B%E7%A1%AC%E4%BB%B6%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E7%9A%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

#### 4.2.3. ASID机制

**ASID机制的作用**：进程在切换的时候，由于 *tlb* 中存放的可能是其他进程的 *tlb* 表项，所以需要在切换的时候进行清空工作（即使所有的 *tlb* 表项无效，地址转移需要遍历多级页表，找到页表项，然后重新加载页表项到 *tlb*），有了 *ASID* 机制之后，**命中 tlb 表项，由虚拟地址和 ASID 共同决定（当然还有 nG 位）**，可以减少进程切换中 *tlb* 被清空的机会。

**ASID**（Address Space Identifer 空间地址标识符）：用以区别不同进程的页表项，在 *arm64* 中，可以选择两种 *ASID* 长度（8 位或 16 位），以下按照 8 位来讲解：

如果 *ASID* 长度为８位，那么 *ASID* 有 256 个值，但是由于０是保留的，所有可以分配的 *ASID* 范围就为 [1, 255]，那么可以标识 255 个进程，当超出 255 个进程的时候，会出现两个进程的ＡSID相同的情况，因此内核使用了ＡSID版本号。内核中处理如下(参考arch/arm64/mm/context.c):

1. 内核为每个进程分配一个 64 位的软件 *ASID*，其中低８位为硬件 *ASID*，高 56 位为 *ASID* 版本号，这个软件 *ASID* 存放放在进程的 `mm_struct` 结构的 `context` 结构的 id 中,进程创建的时候会初始化为 0。
2. 内核中有一个 64 位的全局变量 `asid_generation`，同样它的高 56 位为 *ASID* 版本号，用于标识当前 *ASID* 分配的批次。
3. 当进程调度，由 prev 进程切换到 next 进程的时候，如果不是内核线程则进行地址空间切换调用`check_and_switch_context`，此函数会判断 next 进程的 *ASID* 版本号是否和全局的 *ASID* 版本号相同（是否处于同一批次），如果相同则不需要为 next 进程分配ASID,不相同则需要分配 *ASID*。
4. 内核使用 `asid_map` 位图来管理硬件 *ASID* 的分配，`asid_bits` 记录使用的ASID的长度，每处理器变量`active_asids` 保存当前分配的硬件 *ASID*，每处理器变量 `reserved_asids` 存放保留的 *ASID*，`tlb_flush_pending` 位图记录需要清空 *tlb* 的 cpu 集合。

硬件ASID分配策略如下：

1. 如果进程的 *ASID* 版本号和当前全局的 *ASID* 版本号相同（同批次情况），则不需要重新分配ASID。
2. 如果进程的 *ASID* 版本号和当前全局的 *ASID* 版本号不相同（不同批次情况），且进程原本的硬件 *ASID*已经被分配，则重新分配新的硬件 *ASID*，并将当前全局的 *ASID* 版本号组合新分配的硬件 *ASID* 写到进程的软件 *ASID* 中。
3. 如果进程的 *ASID* 版本号和当前全局的 *ASID* 版本号不相同（不同批次情况），且进程原本的硬件 *ASID* 还没有被分配，则不需要重新分配新的硬件 *ASID*，只需要更新进程软件 *ASID* 版本号，并将当前全局的 *ASID* 版本号组合进程原来的硬件 *ASID* 写到进程的软件 *ASID* 中。
4. 如果进程的 *ASID* 版本号和当前全局的 *ASID* 版本号不相同（不同批次情况），需要分配硬件 *ASID* 时，发现硬件 *ASID* 已经被其他进程分配完（`asid_map` 位图中查找，发现位图全１），则这个时候需要递增全局的 *ASID* 版本号,　清空所有 cpu 的 *tlb*,　清空 `asid_map` 位图，然后分配硬件 *ASID*，并将当前全局的 *ASID* 版本号组合新分配的硬件 *ASID* 写到进程的软件 *ASID* 中。

![PNG-ASID的分配图解Base64](../../pic/operating%20system/ASID%E5%88%86%E9%85%8D%E5%9B%BE%E8%A7%A3.png)

## 5. 线程

### 5.1. 什么是线程

<font color=Crimson>线程是系统独立运行/独立调度的最小单位</font>，它存在于进程中，它包含了线程ID，程序计数器，寄存器集合以及堆栈，这些是每个线程独享的。它与属于同一进程的其他线程共享代码段，数据段和其他的操作系统资源。

<font color=DeepPink>个人理解：多个进程运行起来后，CPU 其实是在调度这些进程中的线程执行，对于单核 CPU 来说，相当于是先将时间片分配给某个进程，然后执行该进程里的某个线程（CPU 上真正运行的是线程）。</font>

### 5.2. 线程的分类

线程可分为：**用户级线程** 和 **内核级线程**

**用户级线程**：它是通过线程库提供的创建，调度和管理的。但是这样有一个缺点，就是内核不知道用户级线程的存在。如果内核是单线程的，那么用户级线程的执行如果引起阻塞，那么将会引起整个进程阻塞。不会切换到下一个进程。

**内核级线程**：内核级线程由操作系统直接支持，内核在其空间内执行线程创建，调度和管理。由于线程也要在内核中注册，所以比起用户级线程，内核级线程的创建和管理要慢一些。但是好处是当一个线程阻塞时，内核能调度该进程内的另外一个线程来执行。而不是直接导致该进程阻塞，切换到下一个进程去执行。

**线程与进程的区别**：

1. 进程拥有自己的资源空间，一个进程包含若干线程，线程与 CPU 资源分配无关（CPU时间片等资源是分配给进程的），进程内的线程共享进程内的资源。
2. 线程的调度与切换比进程快很多

> 注：<font color=Crimson>CPU 密集型（各种循环处理、计算等）：使用多进程实现（因为无需频繁调度）；I/O 密集型（文件处理、网络爬虫等）：使用多线程实现（需要频繁切换）</font>

#### 5.2.1. 用户级线程与内核级线程的区别

<font color=Crimson>内核级线程需要在用户态和核心态里面跑，在用户态里跑需要一个用户栈，在核心态里面跑需要一个核心栈。用户栈和核心栈合起来称为一套栈。</font>这就是核心级线程与用户级线程一个很重要的区别，从一个栈变成了一套栈。用户级线程用 TCB 切换栈的时候是在一个栈与另外一个栈之间切换，核心级线程就是在一套栈与另外一套栈之间的切换（核心级线程切换），核心级线程的 TCB 应该是在内核态里面。

**用户栈与内核栈之间的联系**：

![PNG-用户栈与内核栈之间的联系Base64](../../pic/operating%20system/PNG-%E7%94%A8%E6%88%B7%E6%A0%88%E4%B8%8E%E5%86%85%E6%A0%B8%E6%A0%88%E4%B9%8B%E9%97%B4%E7%9A%84%E8%81%94%E7%B3%BB.jfif)

内核栈什么时候出现？当线程进入内核的时候就应该建立一个属于这个线程的内核栈，那么线程是如何进入系统内核的？通过INT中断。当线程下一次进入内核的时候，操作系统可以根据一些硬件寄存器来知道这个哪个线程，它对应的内核栈在哪里。同时会将用户态的栈的位置（SS、SP）和程序执行到哪个地方了（CS、IP）都压入内核栈。等线程在内核里面执行完（也就是IRET指令）之后就根据进入时存入的SS、SP的值找到用户态中对应栈的位置，根据存入的CS、IP的值找到程序执行到哪个地方。

例子：

    100:A()
    {
     B();
     104:
    }

    200:B()
    {
     read();
     204:
    }

    300:read()
    {
     int 0x80;
     304:
    }

    ---------------------------------

    system_call:
     call sys_read;
    1000:
    2000:sys_read(){}

上面的“-----”表示用户态和核心态的分界；首先该线程调用B函数，将104压栈（用户栈），进入B函数之后调用read()这个系统调用，同时将204压栈（用户栈），进入read()系统调用通过int0x80这个中断号进入内核态，通过系统调用执行到 sys_read

    sys_read()
    { 
     读磁盘；
     将自己变成阻塞状态；
     找到next(下一个执行的线程)；
     调用switch_to(cur,next);
    }

switch_to()方法就是切换线程，形参cur表示当前线程的TCB，next表示下一个执行线程的TCB。这个函数首先将目前esp寄存器的值存入cur.TCB.esp，将next.TCB.esp放入esp寄存器里面；其实就是从当前线程的内核栈切换到next线程的内核栈。这里要明白一件事，内核级线程自己的代码还是在用户态的，只是进入内核态完成系统调用，也就是逛一圈之后还是要回去执行的。因此切换到next线程就是要根据next线程的内核栈找到这个线程阻塞前执行到的位置，并接着执行。所以切换到next线程的内核栈之后应该通过一条包含IRET指令的语句进入到用户态执行这个线程的代码。这样就从cur线程切换到next线程。

### 5.3. Linux线程模型

#### 5.3.1. 一对一的线程模型

LinuxThreads与NPTL均采用 **一对一的线程模型**，<font color=Crimson>一个用户线程对应一个内核线程</font>。内核负责每个线程的调度，可以调度到其他处理器上面。Linux 2.6默认使用NPTL线程库，一对一的线程模型。

**优点**：实现简单

**缺点**：

1. 对用户线程的大部分操作都会映射到内核线程上，引起用户态和内核态的频繁切换。
2. 内核为每个线程都映射调度实体，如果系统出现大量线程，会对系统性能有影响。(这样的模型必须限制线程的数量。)

#### 5.3.2. 多对一的线程模型

多个用户线程对应到同一个内核线程上，线程的创建、调度、同步的所有细节全部由进程的用户空间线程库来处理。<font color=Crimson>任意时刻只能有一个线程访问内核。</font>在不支持内核级线程的ＯS上实现的用户级线程都是这种模型。

**优点**：用户线程的很多操作对内核来说都是透明的，不需要用户态和内核态的频繁切换。使线程的创建、调度、同步等非常快。

**缺点**：

1. 由于多个用户线程对应到同一个内核线程，如果其中一个用户线程阻塞，那么该其他用户线程也无法执行。
2. 内核并不知道用户态有哪些线程，无法像内核线程一样实现较完整的调度、优先级等

#### 5.3.3. 多对多模型

多对多线程模型解决了这一问题：m个用户线程对应到n个内核线程上，通常m>n。由IBM主导的NGPT采用了多对多的线程模型，不过现在已废弃。

**优点**：

1. 兼具多对一模型的优点，并且由于对应了多个内核线程，则一个用户线程阻塞时，其他用户线程仍然可以执行。
2. 由于对应了多个内核线程，则可以实现较完整的调度、优先级等

**缺点**：实现复杂。

### 5.4. 线程切换

#### 5.4.1. 线程切换的流程

线程上下文切换的流程：

1. 挂起当前线程：保存当前线程 CPU 上下文，也就是各类寄存器的信息。
2. 触发 **软中断**，从用户态切换至内核态，恢复内核的寄存器信息，内核栈会执行对应的线程切换函数，从就绪线程中选出一个线程来执行，并恢复线程的CPU上下文。（<font color=Crimson>这里进行了两次 CPU 上下文切换</font>）
3. 对应线程开始执行

> 注：<font color=DeepPink>所谓的 CPU 上下文，就是一堆寄存器中保存的信息，里面保存有 CPU 运行任务所需的信息：</font>
>
> 1. 从哪里开始运行：%rip 指令指针寄存器，标识 CPU 运行的下一条指令
> 2. 栈顶位置：%rsp 是堆栈指针寄存器，通常会指向栈顶位置。
> 3. 当前栈帧在哪：%rbp 是栈帧指针，用于标识当前栈帧的起始位置
> 4. 其他 CPU 的中间状态或结果：%rbx、%r12、%r13等

> 注：<font color=DeepPink>linux 采用的一对一的线程模型，用户线程切换于内核线程切换之间的差异非常小</font>

#### 5.4.2. 什么时候会发生线程切换

1. 时间片轮转：该线程消耗完了 CPU 分配给它的时间片
2. 线程阻塞，线程主动放弃了时间片：比如通过 Thread.sleep()、Object.wait()、Thread.yeild()、Thread.join() 以及 LockSupport.park() 等操作让出了时间片
3. 被动放弃了时间片：比如有一个优先级更高的线程需要运行。

#### 5.4.3. 线程切换的开销

1. 直接开销：操作系统保存与恢复上下文所需的开销、线程调度器调度线程的开销、用户态与内核态切换的开销。
2. 间接开销：是直接开销的副作用，取决于系统实现和用户代码实现。
3. 缓存缺失：切换后需要执行新的逻辑，如果二者的访问的地址空间不相近，则会引起缓存缺失，具体影响范围取决于系统实现和用户代码实现。如果系统的缓存较大，则能减小缓存缺失的影响；如果用户线程访问数据的地址空间接近，则本身的缓存缺失率也比较低（对页表等快慢表式结构同理）。

### 5.5. 多核CPU和多处理器的区别

多核是共用了MMU和Cache等系统资源，但是多处理器则是每个处理器都有一套属于自己的MMU和Cache。没有多核就没有多线程。多核的模型完美处理了多线程。

![PNG-多核CPU与多处理器的区别Base64](../../pic/operating%20system/PNG-%E5%A4%9A%E6%A0%B8CPU%E4%B8%8E%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E5%8C%BA%E5%88%AB.png)

## 6. 协程

### 6.1. 什么是协程

**协程**：又称微线程，纤程。英文名Coroutine。协程是存在于线程之上，包含在线程内部的，相当于是将一个线程执行的任务划分成几个可以异步执行的子任务，每个子任务由一个协程负责执行，这些协程是通过时间片轮询的方式来实现异步执行的。

![PNG-协程执行示意图Base64](../../pic/operating%20system/PNG-%E5%8D%8F%E7%A8%8B%E6%89%A7%E8%A1%8C%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

<font color=Crimson>一个线程内的多个协程的运行是串行的</font>，这点和多进程（多线程）在多核CPU上执行时是不同的。 多进程（多线程）在多核CPU上是可以并行的。<font color=Crimson>当线程内的某一个协程运行时，其它协程必须挂起。</font>

**协程的优点**：

1. 在有大量IO操作业务的情况下，我们采用协程替换线程，可以到达很好的效果，一是降低了系统内存，二是减少了系统切换开销，因此系统的性能也会提升。（无需线程上下文切换的开销）
2. 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。（无需原子操作锁定及同步的开销）

### 6.2. 为什么需要协程

我们都知道多线程，当需要同时执行多项任务的时候，就会采用多线程并发执行。拿手机支付举例子，当收到付款信息的时候，需要查询数据库来判断余额是否充足，然后再进行付款。

假设最开始我们只有可怜的10个用户，收到10条付款消息之后，我们开启启动10个线程去查询数据库，由于用户量很少，结果马上就返回了。第2天用户增加到了100人，你选择增加100个线程去查询数据库，等到第三天，你们加大了优惠力度，这时候有1000人同时在线付款，你按照之前的方法，继续采用1000个线程去查询数据库，并且隐隐觉察到有什么不对。

![PNG-为什么需要协程-不断增长的线程示意图Base64](../../pic/operating%20system/PNG-%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%8D%8F%E7%A8%8B-%E4%B8%8D%E6%96%AD%E5%A2%9E%E9%95%BF%E7%9A%84%E7%BA%BF%E7%A8%8B%E7%A4%BA%E6%84%8F%E5%9B%BE.jfif)

几天之后，见势头大好，运营部门开始不停的补贴消费券，展开了史无前例的大促销，你们的用户开始爆炸增长，这时候有10000人同时在线付款，你打算启动10000个线程来处理任务。等等，问题来了，因为每个线程至少会占用4M的内存空间，10000个线程会消耗39G的内存，而服务器的内存配置只有区区8G，这时候你有2种选择，一是选择增加服务器，二是选择提高代码效率。那么是否有方法能够提高效率呢？

我们知道操作系统在线程等待IO的时候，会阻塞当前线程，切换到其它线程，这样在当前线程等待IO的过程中，其它线程可以继续执行。当系统线程较少的时候没有什么问题，但是当线程数量非常多的时候，却产生了问题:

1. 系统线程会占用非常多的内存空间
2. 过多的线程切换会占用大量的系统时间。

协程刚好可以解决上述2个问题：

1. 协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。
2. <font color=DeepPink>协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。</font>

回到上面的问题，我们只需要启动100个线程，每个线程上运行100个协程，这样不仅减少了线程切换开销，而且还能够同时处理10000个读取数据库的任务，很好的解决了上述任务。

### 6.3. 协程的切换

**协程的切换**<font color=Crimson>就是把当前协程的 CPU 寄存器状态保存起来，然后将需要切换进来的协程的 CPU 状态加载进来。</font>

<font color=Crimson>协程的切换是在用户态进行的</font>，一般来说一次协程上下文的切换最多就是几十纳秒这个量级（linux 上的协程切换是通过 libco 库完成的）。

### 6.4. 协程的问题

#### 6.4.1. 不能在协程中调用阻塞I/O的操作

<font color=Crimson>协程只有在等待IO的过程中才能重复利用线程，也就是说协程本质是通过多路复用来完成的。</font>但是因为协程本身不是线程，只是一个特殊的函数，它不能被操作系统感知到（操作系统只能感知到进程和内核级线程），如果某个线程中的协程调用了阻塞IO，那么将会导致线程切换发生：<font color=DeepPink>操作系统会让线程进入阻塞状态，当前的协程和其它绑定在该线程之上的协程都会陷入阻塞而得不到调度</font>，这往往是不能接受的。

<font color=Crimson>因此在协程中不能调用导致线程阻塞的操作。也就是说，协程只有和异步IO结合起来，才能发挥最大的威力。</font>

那么如何处理在协程中调用阻塞IO的操作呢？一般有2种处理方式

1. 在调用阻塞IO操作的时候，重新启动一个线程去执行这个操作，等执行完成后，协程再去读取结果。这其实和多线程没有太大区别。
2. 对系统的IO进行封装，改成异步调用的方式，这需要大量的工作，最好寄希望于编程语言原生支持。

<font color=Crimson>大并发下的最佳实践就是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。</font>

#### 6.4.2. 不适用于计算密集型任务

计算密集型的任务本身不需要大量的线程切换，因此协程的作用也十分有限，反而还增加了协程切换的开销。
